{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NIzYAK7f7O5"
      },
      "source": [
        "# Dataset Preprocessing for Evaluating Claim Decomp Models\n",
        "\n",
        "This script preprocesses the reconstructed dataset from `chen-etal-2022-generating `,University of Texas, for evaluating our fine-tuned claim decomposition models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaZ9GRmphm7u"
      },
      "source": [
        "## Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I0zD1nNAf1B7",
        "outputId": "46331c25-789d-4b0f-ddcf-ba21348fcf62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4) (2.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests) (2.0.12)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting allennlp==2.7\n",
            "  Downloading allennlp-2.7.0-py3-none-any.whl (738 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.3/738.3 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.9/dist-packages (from allennlp==2.7) (4.65.0)\n",
            "Collecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.9/dist-packages (from allennlp==2.7) (7.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from allennlp==2.7) (1.22.4)\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from allennlp==2.7) (3.8.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from allennlp==2.7) (1.10.1)\n",
            "Collecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.19.1.tar.gz (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.6/593.6 KB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.9/dist-packages (from allennlp==2.7) (2.27.1)\n",
            "Collecting wandb<0.13.0,>=0.10.0\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting base58\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting lmdb\n",
            "  Downloading lmdb-1.4.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.9/305.9 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairscale==0.4.0\n",
            "  Downloading fairscale-0.4.0.tar.gz (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting checklist==0.0.11\n",
            "  Downloading checklist-0.0.11.tar.gz (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from allennlp==2.7) (1.2.2)\n",
            "Collecting torch<1.10.0,>=1.6.0\n",
            "  Downloading torch-1.9.1-cp39-cp39-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers<4.10,>=4.1\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlitedict\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.8\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torchvision<0.11.0,>=0.8.1\n",
            "  Downloading torchvision-0.10.1-cp39-cp39-manylinux1_x86_64.whl (22.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.1/22.1 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy<3.2,>=2.1.0\n",
            "  Downloading spacy-3.1.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2.0,>=1.14\n",
            "  Downloading boto3-1.26.102-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from allennlp==2.7) (9.1.0)\n",
            "Collecting datasets<2.0,>=1.2.1\n",
            "  Downloading datasets-1.18.4-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 KB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting termcolor==1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting filelock<3.1,>=3.0\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (from allennlp==2.7) (3.8.0)\n",
            "Collecting google-cloud-storage<1.43.0,>=1.38.0\n",
            "  Downloading google_cloud_storage-1.42.3-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.0/106.0 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting munch>=2.5\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting jupyter>=1.0\n",
            "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: ipywidgets>=7.5 in /usr/local/lib/python3.9/dist-packages (from checklist==0.0.11->allennlp==2.7) (7.7.1)\n",
            "Collecting patternfork-nosql\n",
            "  Downloading patternfork_nosql-3.6.tar.gz (22.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iso-639\n",
            "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.4/167.4 KB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore<1.30.0,>=1.29.102\n",
            "  Downloading botocore-1.29.102-py3-none-any.whl (10.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets<2.0,>=1.2.1->allennlp==2.7) (1.4.4)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from datasets<2.0,>=1.2.1->allennlp==2.7) (2023.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets<2.0,>=1.2.1->allennlp==2.7) (23.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets<2.0,>=1.2.1->allennlp==2.7) (9.0.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage<1.43.0,>=1.38.0->allennlp==2.7) (2.3.2)\n",
            "Requirement already satisfied: google-api-core<3.0dev,>=1.29.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage<1.43.0,>=1.38.0->allennlp==2.7) (2.11.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage<1.43.0,>=1.38.0->allennlp==2.7) (3.19.6)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage<1.43.0,>=1.38.0->allennlp==2.7) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage<1.43.0,>=1.38.0->allennlp==2.7) (1.16.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage<1.43.0,>=1.38.0->allennlp==2.7) (2.16.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.8->allennlp==2.7) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.8->allennlp==2.7) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18->allennlp==2.7) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18->allennlp==2.7) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18->allennlp==2.7) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18->allennlp==2.7) (2.0.12)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.2,>=2.1.0->allennlp==2.7) (2.0.7)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<3.2,>=2.1.0->allennlp==2.7) (0.10.1)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.17-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (668 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m668.8/668.8 KB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.2,>=2.1.0->allennlp==2.7) (6.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.2,>=2.1.0->allennlp==2.7) (3.0.12)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.2,>=2.1.0->allennlp==2.7) (2.4.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.2,>=2.1.0->allennlp==2.7) (67.6.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.2,>=2.1.0->allennlp==2.7) (2.0.8)\n",
            "Collecting wasabi<1.1.0,>=0.8.1\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.2,>=2.1.0->allennlp==2.7) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.2,>=2.1.0->allennlp==2.7) (3.0.8)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.2,>=2.1.0->allennlp==2.7) (0.7.9)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.2,>=2.1.0->allennlp==2.7) (3.1.2)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision<0.11.0,>=0.8.1->allennlp==2.7) (8.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<4.10,>=4.1->allennlp==2.7) (2022.10.31)\n",
            "Collecting transformers<4.10,>=4.1\n",
            "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.9.0-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.8.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.7.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp==2.7) (5.9.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp==2.7) (8.1.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp==2.7) (2.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.18.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 KB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->allennlp==2.7) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pytest->allennlp==2.7) (2.0.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.9/dist-packages (from pytest->allennlp==2.7) (2.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.9/dist-packages (from pytest->allennlp==2.7) (1.1.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from pytest->allennlp==2.7) (22.2.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.9/dist-packages (from pytest->allennlp==2.7) (1.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->allennlp==2.7) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.30.0,>=1.29.102->boto3<2.0,>=1.14->allennlp==2.7) (2.8.2)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m567.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage<1.43.0,>=1.38.0->allennlp==2.7) (1.59.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<1.43.0,>=1.38.0->allennlp==2.7) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<1.43.0,>=1.38.0->allennlp==2.7) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<1.43.0,>=1.38.0->allennlp==2.7) (5.3.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.9/dist-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<1.43.0,>=1.38.0->allennlp==2.7) (1.5.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (7.34.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (3.6.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (5.5.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (3.0.6)\n",
            "Collecting qtconsole\n",
            "  Using cached qtconsole-5.4.1-py3-none-any.whl (120 kB)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.9/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (6.1.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.9/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (6.3.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (6.5.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.2,>=2.1.0->allennlp==2.7) (2.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets<2.0,>=1.2.1->allennlp==2.7) (2022.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp==2.7) (0.18.3)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp==2.7) (4.11.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp==2.7) (4.9.2)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cherrypy\n",
            "  Downloading CherryPy-18.8.0-py2.py3-none-any.whl (348 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.4/348.4 KB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (6.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (4.4.2)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (0.7.5)\n",
            "Collecting jedi>=0.16\n",
            "  Using cached jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (2.14.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (3.0.38)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<1.43.0,>=1.38.0->allennlp==2.7) (0.4.8)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (0.16.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (23.2.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (5.3.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (0.17.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (21.3.0)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (1.8.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (5.8.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->patternfork-nosql->checklist==0.0.11->allennlp==2.7) (2.4)\n",
            "Collecting zc.lockfile\n",
            "  Downloading zc.lockfile-3.0.post1-py3-none-any.whl (9.8 kB)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-9.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.6/100.6 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jaraco.collections\n",
            "  Downloading jaraco.collections-4.0.0-py3-none-any.whl (10 kB)\n",
            "Collecting portend>=2.1.1\n",
            "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (1.2.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (6.0.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (0.7.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (0.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (0.2.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (0.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.9/dist-packages (from pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp==2.7) (40.0.1)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Using cached QtPy-2.3.1-py3-none-any.whl (84 kB)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.6.0-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=36.0.0->pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp==2.7) (1.15.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core>=4.6.1->notebook->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (3.2.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (4.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (0.7.0)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-5.2.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp==2.7) (0.2.6)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (0.5.1)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.11.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp==2.7) (2.21)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter>=1.0->checklist==0.0.11->allennlp==2.7) (0.19.3)\n",
            "Collecting autocommand\n",
            "  Downloading autocommand-2.2.2-py3-none-any.whl (19 kB)\n",
            "Collecting jaraco.context>=4.1\n",
            "  Downloading jaraco.context-4.3.0-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.9/dist-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist==0.0.11->allennlp==2.7) (6.0.2)\n",
            "Collecting inflect\n",
            "  Downloading inflect-6.0.1-py3-none-any.whl (34 kB)\n",
            "Building wheels for collected packages: checklist, fairscale, overrides, termcolor, jsonnet, sqlitedict, iso-639, pathtools, patternfork-nosql, sacremoses, python-docx, sgmllib3k\n",
            "  Building wheel for checklist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for checklist: filename=checklist-0.0.11-py3-none-any.whl size=12165634 sha256=74e6d5c5cf94c48849502d99c7600fd0173faf42710fa302873eeb4fe577fcef\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/48/f4/983e6cfe66fed9979451c546178d6d6f92ba1d6dc5e6add3e4\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.0-py3-none-any.whl size=239940 sha256=21e84cabd56ce5153f3970bf879572a3dcfeabb90b809268002924119ebd4fd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/7a/d4/188823f7218ccb82ea4c4951ece13d3fd2da28855f504c0ca9\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10189 sha256=d8de0c5d4fc1340cc1c3c390f896fdf588beccfaf3013ecd74e09f906bae2a68\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/11/0e/73fdcb3d71d97e33c230900efe85923ee9d49515d050503174\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4845 sha256=ab8fd3536f64f9a47f936f619176e45543ce0ccb97731adaea9a967c8b77a0a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.19.1-cp39-cp39-linux_x86_64.whl size=6333748 sha256=96f918247a0f15d5f75ede5836c6590488a33d52e8493a75998ab185ab6a5dd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/38/9b/973b06cba1df6acc551937b244246969a31f5ef2820331c056\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=cf14a17cda5c82b1a7c45af5e6fc45a59fca577898b350470e3ac499e121a4fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/48/c4/942f7a1d556fddd2348cb9ac262f251873dfd8a39afec5678e\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=168853 sha256=5adee1399cad81cdb48e513288a628f8c8ef0674bcb4e13b0a75064c91e726d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/3f/de/07f35ac2a2cd11ff30224e3fc6fbf458d7fc95effb1f673431\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=d580b7bc3d73f0836ae4f79207e54acbb84d1b8114ce0e3b98d8e0e858976aec\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "  Building wheel for patternfork-nosql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for patternfork-nosql: filename=patternfork_nosql-3.6-py3-none-any.whl size=22332801 sha256=e4c7abac1155cb382c59f672a795e205f30e08d5da528e9b0c2e903406c77ee8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/f8/c1/165dbb1ce03c55f2a5c7e075ef9c1c6ff71b3620fb4dbcda38\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=0091c2000c38a7e00b0f3c6ba09e46ce38e09bf1b738650aa7928a441ce28eb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184505 sha256=0556fdb9aa3001db6494a33dcaf3e9fdba9c6a3fb951241a9122d87c37535b38\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/8b/7c/09ae60c42c7ba4ed2dddaf2b8b9186cb105255856d6ed3dba5\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=48c426aad2b101a6f2c1812cf8fd414fd2065cffba40659fe67329104dcdc716\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/7a/a7/78c287f64e401255dff4c13fdbc672fed5efbfd21c530114e1\n",
            "Successfully built checklist fairscale overrides termcolor jsonnet sqlitedict iso-639 pathtools patternfork-nosql sacremoses python-docx sgmllib3k\n",
            "Installing collected packages: wasabi, tokenizers, termcolor, sqlitedict, sgmllib3k, sentencepiece, pathtools, overrides, lmdb, jsonnet, iso-639, filelock, backports.csv, zc.lockfile, xxhash, typer, torch, tensorboardX, smmap, shortuuid, setproctitle, sentry-sdk, sacremoses, qtpy, python-docx, pydantic, munch, multidict, jmespath, jedi, jaraco.functools, jaraco.context, frozenlist, feedparser, docker-pycreds, dill, base58, autocommand, async-timeout, yarl, transformers, torchvision, thinc, tempora, responses, multiprocess, inflect, huggingface-hub, gitdb, fairscale, cheroot, botocore, aiosignal, spacy, s3transfer, portend, pdfminer.six, jaraco.text, GitPython, aiohttp, wandb, qtconsole, jaraco.collections, boto3, google-cloud-storage, datasets, cherrypy, patternfork-nosql, jupyter, checklist, allennlp\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.1\n",
            "    Uninstalling wasabi-1.1.1:\n",
            "      Successfully uninstalled wasabi-1.1.1\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.2.0\n",
            "    Uninstalling termcolor-2.2.0:\n",
            "      Successfully uninstalled termcolor-2.2.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.10.7\n",
            "    Uninstalling filelock-3.10.7:\n",
            "      Successfully uninstalled filelock-3.10.7\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.7.0\n",
            "    Uninstalling typer-0.7.0:\n",
            "      Successfully uninstalled typer-0.7.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n",
            "      Successfully uninstalled torch-1.13.1+cu116\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.7\n",
            "    Uninstalling pydantic-1.10.7:\n",
            "      Successfully uninstalled pydantic-1.10.7\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.1+cu116\n",
            "    Uninstalling torchvision-0.14.1+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.1+cu116\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.9\n",
            "    Uninstalling thinc-8.1.9:\n",
            "      Successfully uninstalled thinc-8.1.9\n",
            "  Attempting uninstall: inflect\n",
            "    Found existing installation: inflect 6.0.2\n",
            "    Uninstalling inflect-6.0.2:\n",
            "      Successfully uninstalled inflect-6.0.2\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.5.1\n",
            "    Uninstalling spacy-3.5.1:\n",
            "      Successfully uninstalled spacy-3.5.1\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 2.7.0\n",
            "    Uninstalling google-cloud-storage-2.7.0:\n",
            "      Successfully uninstalled google-cloud-storage-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.9.1 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.9.1 which is incompatible.\n",
            "en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.1.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.31 aiohttp-3.8.4 aiosignal-1.3.1 allennlp-2.7.0 async-timeout-4.0.2 autocommand-2.2.2 backports.csv-1.0.7 base58-2.1.1 boto3-1.26.102 botocore-1.29.102 checklist-0.0.11 cheroot-9.0.0 cherrypy-18.8.0 datasets-1.18.4 dill-0.3.6 docker-pycreds-0.4.0 fairscale-0.4.0 feedparser-6.0.10 filelock-3.0.12 frozenlist-1.3.3 gitdb-4.0.10 google-cloud-storage-1.42.3 huggingface-hub-0.13.3 inflect-6.0.1 iso-639-0.4.5 jaraco.collections-4.0.0 jaraco.context-4.3.0 jaraco.functools-3.6.0 jaraco.text-3.11.1 jedi-0.18.2 jmespath-1.0.1 jsonnet-0.19.1 jupyter-1.0.0 lmdb-1.4.0 multidict-6.0.4 multiprocess-0.70.14 munch-2.5.0 overrides-3.1.0 pathtools-0.1.2 patternfork-nosql-3.6 pdfminer.six-20221105 portend-3.1.0 pydantic-1.8.2 python-docx-0.8.11 qtconsole-5.4.1 qtpy-2.3.1 responses-0.18.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97 sentry-sdk-1.18.0 setproctitle-1.3.2 sgmllib3k-1.0.0 shortuuid-1.0.11 smmap-5.0.0 spacy-3.1.7 sqlitedict-2.1.0 tempora-5.2.1 tensorboardX-2.6 termcolor-1.1.0 thinc-8.0.17 tokenizers-0.10.3 torch-1.9.1 torchvision-0.10.1 transformers-4.5.1 typer-0.4.2 wandb-0.12.21 wasabi-0.10.1 xxhash-3.2.0 yarl-1.8.2 zc.lockfile-3.0.post1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp39-cp39-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.9.0) (4.5.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.1\n",
            "    Uninstalling torch-1.9.1:\n",
            "      Successfully uninstalled torch-1.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.1 requires torch==1.9.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm\n",
        "!pip install pandas\n",
        "!pip install beautifulsoup4\n",
        "!pip install argparse\n",
        "!pip install requests\n",
        "!pip install allennlp==2.7\n",
        "!pip install torch==1.9.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2FGVAH1UR2s"
      },
      "source": [
        "# Reconstruct ClaimDecomp Dataset\n",
        "\n",
        "As the inital dataset downloaded from ClaimDecomp contains incomplete fields (like missing claims, person etc), the data has to be reconstructed by processing information from the source articles of each claim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTWquaHTvbwi"
      },
      "source": [
        "##Information on Train.jsonl\n",
        "\n",
        "Removed Invalid Samples: \n",
        "* **717-719**\n",
        "\n",
        "Skipped Samples: \n",
        "1. 241\n",
        "2. 513\n",
        "3. 579\n",
        "4. 586\n",
        "\n",
        "Total Samples: \n",
        "**793**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swm1dtqAg7na"
      },
      "outputs": [],
      "source": [
        "!python3 reconstruct_dataset.py --input_path ./claim_decomp_raw/train.jsonl --output ./Reconstructed/train.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7LISo4aoqxe"
      },
      "source": [
        "##Information on dev.jsonl\n",
        "\n",
        "Removed Invalid Samples: **34-36**\n",
        "\n",
        "Total Samples: **197**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkdA8Yihjkjo",
        "outputId": "91b459a2-06b9-4cdb-985c-84d298b4734f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of Dataframe: 197\n",
            "\n",
            "197it [05:15,  1.60s/it]\n"
          ]
        }
      ],
      "source": [
        "!python3 reconstruct_dataset.py --input_path ./claim_decomp_raw/dev.jsonl --output ./Reconstructed/dev.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9OX1fiuVA8m"
      },
      "source": [
        "##Information on test.jsonl\n",
        "\n",
        "Total Samples: **200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn6qyuNrkLcc",
        "outputId": "7aaf4d1b-2248-4499-941f-7f10b77a07e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of Dataframe: 200\n",
            "\n",
            "200it [06:26,  1.93s/it]\n"
          ]
        }
      ],
      "source": [
        "!python3 reconstruct_dataset.py --input_path ./claim_decomp_raw/test.jsonl --output ./Reconstructed/test.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MCCHdtMPGcE"
      },
      "source": [
        "# Dataframe Creation\n",
        "\n",
        "The following code serves to construct a Pandas dataframe from the raw jsonl files reconstructed from the original ClaimDecomp dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "NkBXLBgCLxNs",
        "outputId": "871bab3e-5d13-4f10-e7cd-a6095d5c5468"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d459fa62-37cd-42cc-9c82-60c0b193674c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>example_id</th>\n",
              "      <th>label</th>\n",
              "      <th>url</th>\n",
              "      <th>annotations</th>\n",
              "      <th>claim</th>\n",
              "      <th>person</th>\n",
              "      <th>venue</th>\n",
              "      <th>justification</th>\n",
              "      <th>full_article</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5088301214328986128</td>\n",
              "      <td>half-true</td>\n",
              "      <td>https://www.politifact.com/factchecks/2018/oct...</td>\n",
              "      <td>[{'questions': ['Has Barr received $36,550 fro...</td>\n",
              "      <td>Says Kentucky Rep. Andy Barr \"would let shady ...</td>\n",
              "      <td>With Honor</td>\n",
              "      <td>stated on September 10, 2018 in a TV ad:</td>\n",
              "      <td>With Honor says Barr \"would let shady payday l...</td>\n",
              "      <td>The \"cross-partisan\" group With Honor, which f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8487672735991906749</td>\n",
              "      <td>barely-true</td>\n",
              "      <td>https://www.politifact.com/factchecks/2018/aug...</td>\n",
              "      <td>[{'questions': ['Did Nicholson make $1 million...</td>\n",
              "      <td>\"New reports show Kevin Nicholson made over $1...</td>\n",
              "      <td>Tammy Baldwin</td>\n",
              "      <td>stated on July 31, 2018 in a TV ad:</td>\n",
              "      <td>Baldwin says: \"New reports show Kevin Nicholso...</td>\n",
              "      <td>U.S. Sen. Tammy Baldwin used a TV ad to attack...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3277676096708619167</td>\n",
              "      <td>pants-fire</td>\n",
              "      <td>https://www.politifact.com/factchecks/2018/apr...</td>\n",
              "      <td>[{'questions': ['Will people be taken into loc...</td>\n",
              "      <td>Says that unless the recipient called back abo...</td>\n",
              "      <td>Anonymous Caller</td>\n",
              "      <td>stated on April 10, 2018 in an anonymous phone...</td>\n",
              "      <td>An automated phone message fielded in Austin s...</td>\n",
              "      <td>A phone message from a New York area code abou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6252140003382293541</td>\n",
              "      <td>half-true</td>\n",
              "      <td>https://www.politifact.com/factchecks/2016/jul...</td>\n",
              "      <td>[{'questions': ['Was Donald Trump \"Excited\" fo...</td>\n",
              "      <td>\"Donald Trump said he was excited for the 2008...</td>\n",
              "      <td>Elizabeth Warren</td>\n",
              "      <td>stated on July 25, 2016 in a speech at the Dem...</td>\n",
              "      <td>Warren said, \"Donald Trump said he was excited...</td>\n",
              "      <td>Sen. Elizabeth Warren's speech at the Democrat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2194277234040896494</td>\n",
              "      <td>barely-true</td>\n",
              "      <td>https://www.politifact.com/factchecks/2016/jun...</td>\n",
              "      <td>[{'questions': ['Has Obama cited climate chang...</td>\n",
              "      <td>\"The president has said the national security ...</td>\n",
              "      <td>Paul Babeu</td>\n",
              "      <td>stated on May 26, 2016 in an interview on Fox ...</td>\n",
              "      <td>Babeu said, \"The president has said the nation...</td>\n",
              "      <td>Paul Babeu, the Republican Sheriff of Pinal Co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d459fa62-37cd-42cc-9c82-60c0b193674c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d459fa62-37cd-42cc-9c82-60c0b193674c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d459fa62-37cd-42cc-9c82-60c0b193674c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            example_id        label  \\\n",
              "0  5088301214328986128    half-true   \n",
              "1  8487672735991906749  barely-true   \n",
              "2  3277676096708619167   pants-fire   \n",
              "3  6252140003382293541    half-true   \n",
              "4 -2194277234040896494  barely-true   \n",
              "\n",
              "                                                 url  \\\n",
              "0  https://www.politifact.com/factchecks/2018/oct...   \n",
              "1  https://www.politifact.com/factchecks/2018/aug...   \n",
              "2  https://www.politifact.com/factchecks/2018/apr...   \n",
              "3  https://www.politifact.com/factchecks/2016/jul...   \n",
              "4  https://www.politifact.com/factchecks/2016/jun...   \n",
              "\n",
              "                                         annotations  \\\n",
              "0  [{'questions': ['Has Barr received $36,550 fro...   \n",
              "1  [{'questions': ['Did Nicholson make $1 million...   \n",
              "2  [{'questions': ['Will people be taken into loc...   \n",
              "3  [{'questions': ['Was Donald Trump \"Excited\" fo...   \n",
              "4  [{'questions': ['Has Obama cited climate chang...   \n",
              "\n",
              "                                               claim            person  \\\n",
              "0  Says Kentucky Rep. Andy Barr \"would let shady ...        With Honor   \n",
              "1  \"New reports show Kevin Nicholson made over $1...     Tammy Baldwin   \n",
              "2  Says that unless the recipient called back abo...  Anonymous Caller   \n",
              "3  \"Donald Trump said he was excited for the 2008...  Elizabeth Warren   \n",
              "4  \"The president has said the national security ...        Paul Babeu   \n",
              "\n",
              "                                               venue  \\\n",
              "0           stated on September 10, 2018 in a TV ad:   \n",
              "1                stated on July 31, 2018 in a TV ad:   \n",
              "2  stated on April 10, 2018 in an anonymous phone...   \n",
              "3  stated on July 25, 2016 in a speech at the Dem...   \n",
              "4  stated on May 26, 2016 in an interview on Fox ...   \n",
              "\n",
              "                                       justification  \\\n",
              "0  With Honor says Barr \"would let shady payday l...   \n",
              "1  Baldwin says: \"New reports show Kevin Nicholso...   \n",
              "2  An automated phone message fielded in Austin s...   \n",
              "3  Warren said, \"Donald Trump said he was excited...   \n",
              "4  Babeu said, \"The president has said the nation...   \n",
              "\n",
              "                                        full_article  \n",
              "0  The \"cross-partisan\" group With Honor, which f...  \n",
              "1  U.S. Sen. Tammy Baldwin used a TV ad to attack...  \n",
              "2  A phone message from a New York area code abou...  \n",
              "3  Sen. Elizabeth Warren's speech at the Democrat...  \n",
              "4  Paul Babeu, the Republican Sheriff of Pinal Co...  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pandas import json_normalize\n",
        "\n",
        "path = \"./reconstructed_data/test.jsonl\"\n",
        "with open(path, 'r') as jsonl_file:\n",
        "    jsonl_list = list(jsonl_file)\n",
        "\n",
        "#listOfRows is a list of dict, each containing data for each row in the df with keys = column name\n",
        "listOfRows = []\n",
        "for entry in jsonl_list:\n",
        "    loadedEntry = json.loads(entry)\n",
        "    listOfRows.append(loadedEntry)\n",
        "\n",
        "df = pd.DataFrame(listOfRows)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "Ke7yuDuePxe6",
        "outputId": "a835d6ec-ab7e-4d44-cc02-a822fb99f95e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-28-31a2801a0383>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dfFiltered['questions'][i] = questions\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6319dc0d-1abe-4c51-a415-a150dda41e59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>label</th>\n",
              "      <th>annotated-questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Says Kentucky Rep. Andy Barr \"would let shady ...</td>\n",
              "      <td>half-true</td>\n",
              "      <td>[Has Barr received $36,550 from payday lenders...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"New reports show Kevin Nicholson made over $1...</td>\n",
              "      <td>barely-true</td>\n",
              "      <td>[Did Nicholson make $1 million consulting for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Says that unless the recipient called back abo...</td>\n",
              "      <td>pants-fire</td>\n",
              "      <td>[Will people be taken into local police custod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Donald Trump said he was excited for the 2008...</td>\n",
              "      <td>half-true</td>\n",
              "      <td>[Was Donald Trump \"Excited\" for the 2008 housi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"The president has said the national security ...</td>\n",
              "      <td>barely-true</td>\n",
              "      <td>[Has Obama cited climate change as the top nat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6319dc0d-1abe-4c51-a415-a150dda41e59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6319dc0d-1abe-4c51-a415-a150dda41e59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6319dc0d-1abe-4c51-a415-a150dda41e59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               claim        label  \\\n",
              "0  Says Kentucky Rep. Andy Barr \"would let shady ...    half-true   \n",
              "1  \"New reports show Kevin Nicholson made over $1...  barely-true   \n",
              "2  Says that unless the recipient called back abo...   pants-fire   \n",
              "3  \"Donald Trump said he was excited for the 2008...    half-true   \n",
              "4  \"The president has said the national security ...  barely-true   \n",
              "\n",
              "                                 annotated-questions  \n",
              "0  [Has Barr received $36,550 from payday lenders...  \n",
              "1  [Did Nicholson make $1 million consulting for ...  \n",
              "2  [Will people be taken into local police custod...  \n",
              "3  [Was Donald Trump \"Excited\" for the 2008 housi...  \n",
              "4  [Has Obama cited climate change as the top nat...  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Select only the claim, label, original questions from the df\n",
        "dfFiltered = df.loc[ : ,['claim', 'label']]\n",
        "dfFiltered['questions'] = np.nan\n",
        "\n",
        "#Combine all subquestions for each claim into a list\n",
        "for i in range(len(df)):\n",
        "  annotationList = df.loc[i, 'annotations']\n",
        "  questions = []\n",
        "  \n",
        "  for j in range(len(annotationList)):\n",
        "    questionSet = annotationList[j]['questions']\n",
        "    questions.extend(questionSet)\n",
        "  \n",
        "  dfFiltered['questions'][i] = questions\n",
        "\n",
        "# Rename the questions row to specify that these are from human annotators\n",
        "dfFiltered.rename(columns={'questions':'annotated-questions'}, inplace=True)\n",
        "dfFiltered.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "g9r-3qAQpFHU"
      },
      "source": [
        "## Further clean data by removing breakline tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "E0yPIhlZo2-x",
        "outputId": "a74744b8-d114-471b-e6f9-62a8a5295fda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before breakline removal:\n",
            "\n",
            "[\"Can sending more girls to school boost a country's GDP?\", 'Do experts agree that putting more girls in school leads to economic growth?', 'Can educating more women possibly lead to a stronger economy?', 'Is there evidence that supports a causal link between increased education of women and economic growth?', 'Is education the only barrier to employment for women?']\n",
            "\n",
            "After breakline removal:\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"1. Can sending more girls to school boost a country's GDP? \\n2. Do experts agree that putting more girls in school leads to economic growth? \\n3. Can educating more women possibly lead to a stronger economy? \\n4. Is there evidence that supports a causal link between increased education of women and economic growth? \\n5. Is education the only barrier to employment for women?\""
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Clean data by removing breaklines \\n\n",
        "def removeBreaklines(df):\n",
        "  for j in range(len(df)):\n",
        "    qsnSeries = df[j]\n",
        "    for i in range(len(qsnSeries)):\n",
        "      # Add qsn numbering for openAI dataset\n",
        "      qsnSeries[i] = str(i+1) + \". \" + qsnSeries[i]\n",
        "      qsnSeries[i] = qsnSeries[i].replace('\\n','')\n",
        "    # Combine questions into a single string\n",
        "    df[j] = \" \\n\".join(df[j])\n",
        "\n",
        "print(\"Before breakline removal:\\n\")\n",
        "print(dfFiltered.loc[100, \"annotated-questions\"])\n",
        "\n",
        "tmp = dfFiltered.loc[ : , 'annotated-questions']\n",
        "removeBreaklines(tmp)\n",
        "\n",
        "print(\"\\nAfter breakline removal:\\n\")\n",
        "dfFiltered.loc[100, \"annotated-questions\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDLv_eyZyk2f"
      },
      "source": [
        "## Preview the state of our Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "D9s8QTu0yjJB",
        "outputId": "698c30b4-8b83-4e45-c2d3-7005ef64c434"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bc908a85-9b00-4db4-b6df-a9a5efa04494\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>label</th>\n",
              "      <th>annotated-questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Says Kentucky Rep. Andy Barr \"would let shady ...</td>\n",
              "      <td>half-true</td>\n",
              "      <td>1. Has Barr received $36,550 from payday lende...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"New reports show Kevin Nicholson made over $1...</td>\n",
              "      <td>barely-true</td>\n",
              "      <td>1. Did Nicholson make $1 million consulting fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Says that unless the recipient called back abo...</td>\n",
              "      <td>pants-fire</td>\n",
              "      <td>1. Will people be taken into local police cust...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Donald Trump said he was excited for the 2008...</td>\n",
              "      <td>half-true</td>\n",
              "      <td>1. Was Donald Trump \"Excited\" for the 2008 hou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"The president has said the national security ...</td>\n",
              "      <td>barely-true</td>\n",
              "      <td>1. Has Obama cited climate change as the top n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc908a85-9b00-4db4-b6df-a9a5efa04494')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc908a85-9b00-4db4-b6df-a9a5efa04494 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc908a85-9b00-4db4-b6df-a9a5efa04494');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               claim        label  \\\n",
              "0  Says Kentucky Rep. Andy Barr \"would let shady ...    half-true   \n",
              "1  \"New reports show Kevin Nicholson made over $1...  barely-true   \n",
              "2  Says that unless the recipient called back abo...   pants-fire   \n",
              "3  \"Donald Trump said he was excited for the 2008...    half-true   \n",
              "4  \"The president has said the national security ...  barely-true   \n",
              "\n",
              "                                 annotated-questions  \n",
              "0  1. Has Barr received $36,550 from payday lende...  \n",
              "1  1. Did Nicholson make $1 million consulting fo...  \n",
              "2  1. Will people be taken into local police cust...  \n",
              "3  1. Was Donald Trump \"Excited\" for the 2008 hou...  \n",
              "4  1. Has Obama cited climate change as the top n...  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfFiltered.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zllf8_jysEv"
      },
      "source": [
        "## We shall reclassify original labels to only 2 categories, True/False for easier evaluation\n",
        "\n",
        "**New True labels are represented by:**\n",
        "\n",
        "Original labels:  \n",
        "1. half-true\n",
        "2. mostly-true\n",
        "3. true\n",
        "\n",
        "**New False labels are represented by:**\n",
        "\n",
        "Original labels:  \n",
        "1. pants-fire\n",
        "2. false\n",
        "3. barely-true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aceEL8WmzYPx",
        "outputId": "f78d7c4f-658c-4def-cfda-542effb3ef8b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5b9a1d9f-dc01-4e64-8e04-39ac2f962cf5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>label</th>\n",
              "      <th>annotated-questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Says Kentucky Rep. Andy Barr \"would let shady ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1. Has Barr received $36,550 from payday lende...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"New reports show Kevin Nicholson made over $1...</td>\n",
              "      <td>0</td>\n",
              "      <td>1. Did Nicholson make $1 million consulting fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Says that unless the recipient called back abo...</td>\n",
              "      <td>0</td>\n",
              "      <td>1. Will people be taken into local police cust...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Donald Trump said he was excited for the 2008...</td>\n",
              "      <td>1</td>\n",
              "      <td>1. Was Donald Trump \"Excited\" for the 2008 hou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"The president has said the national security ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1. Has Obama cited climate change as the top n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b9a1d9f-dc01-4e64-8e04-39ac2f962cf5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b9a1d9f-dc01-4e64-8e04-39ac2f962cf5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b9a1d9f-dc01-4e64-8e04-39ac2f962cf5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               claim  label  \\\n",
              "0  Says Kentucky Rep. Andy Barr \"would let shady ...      1   \n",
              "1  \"New reports show Kevin Nicholson made over $1...      0   \n",
              "2  Says that unless the recipient called back abo...      0   \n",
              "3  \"Donald Trump said he was excited for the 2008...      1   \n",
              "4  \"The president has said the national security ...      0   \n",
              "\n",
              "                                 annotated-questions  \n",
              "0  1. Has Barr received $36,550 from payday lende...  \n",
              "1  1. Did Nicholson make $1 million consulting fo...  \n",
              "2  1. Will people be taken into local police cust...  \n",
              "3  1. Was Donald Trump \"Excited\" for the 2008 hou...  \n",
              "4  1. Has Obama cited climate change as the top n...  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def convert_labels(df):\n",
        "    # map labels to 1 or 0 according to the above classification\n",
        "    label_equivalent = {\n",
        "        'pants-fire': 0,\n",
        "        'false': 0,\n",
        "        'barely-true': 0,\n",
        "        'half-true': 1,\n",
        "        'mostly-true': 1,\n",
        "        'true': 1\n",
        "    }\n",
        "    \n",
        "    # convert the 'label' column values to 1 or 0\n",
        "    df['label'] = df['label'].map(label_equivalent)\n",
        "    return df\n",
        "\n",
        "dfFiltered = convert_labels(dfFiltered)\n",
        "dfFiltered.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_fxXYf_hCgi6"
      },
      "source": [
        "## Exporting Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZgsKJc6cyOcQ"
      },
      "outputs": [],
      "source": [
        "fileName = \"preprocessed_data/test.csv\"\n",
        "dfFiltered.to_csv(fileName, index=False, encoding = 'utf-8-sig', header=True, )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FNU3_gVPCmYD"
      },
      "source": [
        "# Abstracting Dataframe Creation\n",
        "\n",
        "The above cells are abstracted into the filterData method. \n",
        "\n",
        "The following cell represents a condensed version suitable for abstraction into a standalone python file for dataframe creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilvccqjG_OGQ",
        "outputId": "63a15525-d24c-45ef-cbb3-54c3210ab5d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating dev.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 197/197 [00:00<00:00, 26086.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating train.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 793/793 [00:00<00:00, 37043.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating test.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:00<00:00, 23618.57it/s]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pandas import json_normalize\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def convert_labels(df):\n",
        "    # map labels to 1 or 0 according to the above classification\n",
        "    label_equivalent = {\n",
        "        'pants-fire': 0,\n",
        "        'false': 0,\n",
        "        'barely-true': 0,\n",
        "        'half-true': 1,\n",
        "        'mostly-true': 1,\n",
        "        'true': 1\n",
        "    }\n",
        "    \n",
        "    # convert the 'label' column values to 1 or 0\n",
        "    df['label'] = df['label'].map(label_equivalent)\n",
        "    return df\n",
        "\n",
        "# Clean data by removing breaklines \\n\n",
        "def removeBreaklines(df):\n",
        "  for j in range(len(df)):\n",
        "    qsnSeries = df[j]\n",
        "    for i in range(len(qsnSeries)):\n",
        "      # Add qsn numbering for openAI dataset\n",
        "      qsnSeries[i] = str(i+1) + \". \" + qsnSeries[i]\n",
        "      qsnSeries[i] = qsnSeries[i].replace('\\n','')\n",
        "    # Combine questions into a single string\n",
        "    df[j] = \" \\n\".join(df[j])\n",
        "\n",
        "# Selects and returns clean data\n",
        "def preprocessData(sourcePath, destPath):\n",
        "  \n",
        "  #Load jsonl file\n",
        "  with open(sourcePath, 'r') as jsonl_file:\n",
        "      jsonl_list = list(jsonl_file)\n",
        "\n",
        "  #listOfRows is a list of dict, each dict containing data for a row in the df with keys = column name\n",
        "  listOfRows = []\n",
        "  for entry in jsonl_list:\n",
        "      loadedEntry = json.loads(entry)\n",
        "      listOfRows.append(loadedEntry)\n",
        "\n",
        "  #Convert list of dict into a df\n",
        "  df = pd.DataFrame(listOfRows)\n",
        "\n",
        "  #Select only the claim, label, original questions from the df\n",
        "  dfFiltered = df.loc[ : ,['claim', 'label']]\n",
        "  dfFiltered['questions'] = np.nan\n",
        "\n",
        "  #Combine all subquestions for each claim into a list\n",
        "  for i in tqdm(range(len(df))):\n",
        "    annotationList = df.loc[i, 'annotations']\n",
        "    questions = []\n",
        "    \n",
        "    for j in range(len(annotationList)):\n",
        "      questionSet = annotationList[j]['questions']\n",
        "      questions.extend(questionSet)\n",
        "    \n",
        "    dfFiltered['questions'][i] = questions\n",
        "\n",
        "  # Rename the questions row to specify that these are from human annotators\n",
        "  dfFiltered.rename(columns={'questions':'annotated-questions'}, inplace=True)\n",
        "\n",
        "  #Remove breakline tokens \n",
        "  tmp = dfFiltered.loc[ : , 'annotated-questions']\n",
        "  removeBreaklines(tmp)\n",
        "  dfFinal = convert_labels(dfFiltered)\n",
        "\n",
        "  #Export filtered df to csv\n",
        "  # dfFiltered.to_csv(destPath, index=False, encoding = 'utf-8-sig', header=True, )\n",
        "  \n",
        "  #Export filtered df to csv [openAI]\n",
        "  dfFinal.to_csv(destPath, index=False, encoding = 'utf-8-sig', header=True, )\n",
        "\n",
        "  #Export filtered df to json\n",
        "  # dfFiltered.to_json(destPath, orient='table', index=False)\n",
        "\n",
        "#File Paths\n",
        "devSource = \"./reconstructed_data/dev.jsonl\"\n",
        "devDest = \"./preprocessed_data/dev.csv\"\n",
        "\n",
        "trainSource = \"./reconstructed_data/train.jsonl\"\n",
        "trainDest = \"./preprocessed_data/train.csv\"\n",
        "\n",
        "testSource = \"./reconstructed_data/test.jsonl\"\n",
        "testDest = \"./preprocessed_data/test.csv\"\n",
        "\n",
        "#Data Extraction\n",
        "print(\"Creating dev.csv\")\n",
        "preprocessData(devSource, devDest)\n",
        "\n",
        "print(\"\\nCreating train.csv\")\n",
        "preprocessData(trainSource, trainDest)\n",
        "\n",
        "print(\"\\nCreating test.csv\")\n",
        "preprocessData(testSource, testDest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F33MNoSvFYcy",
        "outputId": "45a68f08-f9d8-49fb-bb40-a28920a2604a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating dev.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 197/197 [00:00<00:00, 26484.96it/s]\n"
          ]
        }
      ],
      "source": [
        "#File Paths\n",
        "devSource = \"./reconstructed_data/dev.jsonl\"\n",
        "devDest = \"./filtered_data/dev.json\"\n",
        "\n",
        "#Data Extraction\n",
        "print(\"Creating dev.json\")\n",
        "preprocessData(devSource, devDest)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
