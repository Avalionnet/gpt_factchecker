{"cells":[{"cell_type":"markdown","metadata":{"id":"5NIzYAK7f7O5"},"source":["# Fine Tuning a GPT3 NLP Model for complex claim decomposition\n","In our attempt to improve the final veracity score for automated fact checking systems, we research whether decomposing complex claims into binary sub-claims will help to improve entailment classification for NLI models. \n","\n","To do so, we will train a GPT3 model to decompose complex input claims into binary sub-questions to better tackle different aspects of the claim.\n","\n","This script uses a preprocessed version of the ClaimDecomp dataset specified in the `chen-etal-2022-generating ` paper by the University of Texas."]},{"cell_type":"markdown","metadata":{"id":"jaZ9GRmphm7u"},"source":["## Install Required Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":490218,"status":"ok","timestamp":1679894641390,"user":{"displayName":"Ming Lim Low","userId":"17425575695973941585"},"user_tz":-480},"id":"I0zD1nNAf1B7","outputId":"dbc126ef-654b-468a-9d5e-65bc0311d205"},"outputs":[],"source":["!pip install tqdm\n","!pip install pandas\n","!pip install beautifulsoup4\n","!pip install argparse\n","!pip install requests\n","!pip install allennlp==2.7\n","!pip install torch==1.9.0"]},{"cell_type":"markdown","metadata":{"id":"s6QQ3SbEl-UV"},"source":["## Loading the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5D24QhJenC1D"},"outputs":[],"source":["!pip install --upgrade pip setuptools\n","!pip install unicodecsv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AK_WQtCTl-BG"},"outputs":[],"source":["import csv\n","import json\n","\n","csv_path = \"./filtered_data/train.csv\"\n","jsonl_path = \"./filtered_jsonl/train.jsonl\"\n","\n","# Read the CSV file and convert it to a list of dictionaries\n","with open(csv_path, \"r\", encoding=\"utf-8-sig\") as csv_file, open(jsonl_path, \"w\", encoding=\"utf-8\") as jsonl_file:\n","    csv_reader = csv.DictReader(csv_file)\n","    for row in csv_reader:\n","        jsonl_data = {\"prompt\": row[\"prompt\"], \"completion\": row[\"completion\"]}\n","        jsonl_file.write(json.dumps(jsonl_data, ensure_ascii=False) + \"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"7X24nh65Ykj6"},"source":["# Train OpenAi model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13641,"status":"ok","timestamp":1679975038915,"user":{"displayName":"Ming Lim Low","userId":"17425575695973941585"},"user_tz":-480},"id":"18msBHrhKU-t","outputId":"2b1b6ace-fbb1-4b23-a235-cf50bfacf601"},"outputs":[],"source":["pip install --upgrade openai"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1679975038916,"user":{"displayName":"Ming Lim Low","userId":"17425575695973941585"},"user_tz":-480},"id":"P41N0pBvRsD2","outputId":"a44364a6-08b3-4e17-a40b-3e0a2ca278fc"},"outputs":[],"source":["%env OPENAI_API_KEY=[INSERT YOUR OPENAI KEY HERE]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Au7NCvswR8eq"},"outputs":[],"source":["import openai"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Final preprocessing for your training dataset using OpenAI's CLI tool"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19869,"status":"ok","timestamp":1679938653034,"user":{"displayName":"Ming Lim Low","userId":"17425575695973941585"},"user_tz":-480},"id":"TffhfH3LWZRL","outputId":"cef8eac1-6a25-44a8-84d8-b873b18b60d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Analyzing...\n","\n","- Your file contains 793 prompt-completion pairs\n","- All prompts end with suffix `\\nsub-questions:`. This suffix seems very long. Consider replacing with a shorter suffix, such as `\\n\\n###\\n\\n`\n","- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n","- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n","\n","Based on the analysis we will perform the following actions:\n","- [Recommended] Add a suffix ending ` END` to all completions [Y/n]: Y\n","- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n","\n","\n","Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n","\n","Wrote modified file to `./filtered_jsonl/train_prepared.jsonl`\n","Feel free to take a look!\n","\n","Now use that file when fine-tuning:\n","> openai api fine_tunes.create -t \"./filtered_jsonl/train_prepared.jsonl\"\n","\n","After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\nsub-questions:` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" END\"]` so that the generated texts ends at the expected place.\n","Once your model starts training, it'll approximately take 13.33 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"]}],"source":["# ./filtered_jsonl/train.jsonl refers to the file location of the dataset you wish to fine-tune with. Feel free to modify this.\n","!openai tools fine_tunes.prepare_data -f ./filtered_jsonl/train.jsonl"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Fine-tuning with the dataset prepared"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64772,"status":"ok","timestamp":1679939084342,"user":{"displayName":"Ming Lim Low","userId":"17425575695973941585"},"user_tz":-480},"id":"WRFSb1NQWj-H","outputId":"57ec1f76-7548-465c-c7b3-645c8c7a8c32"},"outputs":[{"name":"stdout","output_type":"stream","text":["\rUpload progress:   0% 0.00/1.07M [00:00<?, ?it/s]\rUpload progress: 100% 1.07M/1.07M [00:00<00:00, 818Mit/s]\n","Uploaded file from ./filtered_jsonl/train_prepared.jsonl: file-LAP6Eb5w6BYKqZywGu9ilbrw\n","Created fine-tune: ft-NipGhN0IwwTPx4jUKO8NoGyr\n","Streaming events until fine-tuning is complete...\n","\n","(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n","[2023-03-27 17:43:42] Created fine-tune: ft-NipGhN0IwwTPx4jUKO8NoGyr\n","\n","Stream interrupted (client disconnected).\n","To resume the stream, run:\n","\n","  openai api fine_tunes.follow -i ft-NipGhN0IwwTPx4jUKO8NoGyr\n","\n"]}],"source":["# Adding a suffix here is optional, exists to help you better identify the difference between different fine-tuned versions.\n","!openai api fine_tunes.create -t ./filtered_jsonl/train_prepared.jsonl -m davinci --suffix \"train-append-subQ\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_HiS_PghpUH"},"outputs":[],"source":["# To cancel fine-tuning job\n","!openai api fine_tunes.cancel -i [YOUR FINE-TUNING JOB ID, for eg. here its ft-Rz3v9tzlfifRFTZI8AEwIPz7]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3467,"status":"ok","timestamp":1679975058872,"user":{"displayName":"Ming Lim Low","userId":"17425575695973941585"},"user_tz":-480},"id":"d4U-f1nKYuN-","outputId":"3464ddcc-0b57-40c1-f6b9-4d4cd73c7cdf"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023-03-27 17:43:42] Created fine-tune: ft-NipGhN0IwwTPx4jUKO8NoGyr\n","[2023-03-27 17:47:31] Fine-tune costs $27.25\n","[2023-03-27 17:47:31] Fine-tune enqueued\n","[2023-03-27 17:48:14] Fine-tune is in the queue. Queue number: 31\n","[2023-03-27 17:48:39] Fine-tune is in the queue. Queue number: 30\n","[2023-03-27 17:49:24] Fine-tune is in the queue. Queue number: 29\n","[2023-03-27 17:51:17] Fine-tune is in the queue. Queue number: 28\n","[2023-03-27 17:51:51] Fine-tune is in the queue. Queue number: 27\n","[2023-03-27 17:52:57] Fine-tune is in the queue. Queue number: 26\n","[2023-03-27 17:53:45] Fine-tune is in the queue. Queue number: 25\n","[2023-03-27 17:55:37] Fine-tune is in the queue. Queue number: 24\n","[2023-03-27 17:56:06] Fine-tune is in the queue. Queue number: 23\n","[2023-03-27 17:57:30] Fine-tune is in the queue. Queue number: 22\n","[2023-03-27 18:01:40] Fine-tune is in the queue. Queue number: 21\n","[2023-03-27 18:01:48] Fine-tune is in the queue. Queue number: 20\n","[2023-03-27 18:01:58] Fine-tune is in the queue. Queue number: 19\n","[2023-03-27 18:02:07] Fine-tune is in the queue. Queue number: 18\n","[2023-03-27 18:05:15] Fine-tune is in the queue. Queue number: 17\n","[2023-03-27 18:05:28] Fine-tune is in the queue. Queue number: 16\n","[2023-03-27 18:05:47] Fine-tune is in the queue. Queue number: 15\n","[2023-03-27 18:06:45] Fine-tune is in the queue. Queue number: 14\n","[2023-03-27 18:08:27] Fine-tune is in the queue. Queue number: 13\n","[2023-03-27 18:08:35] Fine-tune is in the queue. Queue number: 12\n","[2023-03-27 18:09:42] Fine-tune is in the queue. Queue number: 11\n","[2023-03-27 18:11:12] Fine-tune is in the queue. Queue number: 10\n","[2023-03-27 18:12:00] Fine-tune is in the queue. Queue number: 9\n","[2023-03-27 18:13:39] Fine-tune is in the queue. Queue number: 8\n","[2023-03-27 18:15:50] Fine-tune is in the queue. Queue number: 7\n","[2023-03-27 18:15:52] Fine-tune is in the queue. Queue number: 6\n","[2023-03-27 18:16:05] Fine-tune is in the queue. Queue number: 5\n","[2023-03-27 18:16:27] Fine-tune is in the queue. Queue number: 4\n","[2023-03-27 18:16:59] Fine-tune is in the queue. Queue number: 3\n","[2023-03-27 18:19:03] Fine-tune is in the queue. Queue number: 2\n","[2023-03-27 18:19:15] Fine-tune is in the queue. Queue number: 1\n","[2023-03-27 18:19:30] Fine-tune is in the queue. Queue number: 0\n","[2023-03-27 18:20:15] Fine-tune started\n","[2023-03-27 18:28:11] Completed epoch 1/4\n","[2023-03-27 18:34:23] Completed epoch 2/4\n","[2023-03-27 18:40:28] Completed epoch 3/4\n","[2023-03-27 18:46:41] Completed epoch 4/4\n","[2023-03-27 18:47:22] Uploaded model: davinci:ft-personal:train-append-subq-2023-03-27-18-47-21\n","[2023-03-27 18:47:23] Uploaded result file: file-lAub7teYrzUzbXXBBEVhRWKc\n","[2023-03-27 18:47:23] Fine-tune succeeded\n","\n","Job complete! Status: succeeded ðŸŽ‰\n","Try out your fine-tuned model:\n","\n","openai api completions.create -m davinci:ft-personal:train-append-subq-2023-03-27-18-47-21 -p <YOUR_PROMPT>\n"]}],"source":["# To follow up on the fine-tuning progress\n","!openai api fine_tunes.follow -i [YOUR FINE-TUNING JOB ID, for eg. here its ft-Rz3v9tzlfifRFTZI8AEwIPz7]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f9s5Pg6JqsSq"},"outputs":[],"source":["# To pull up the available flags for completions\n","!openai api completions.create -h"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPAOKyqtEEYTWLMpoRLzW5s","mount_file_id":"1EWV_OBoegSkFwNqHpKwa3UzmeX8RVJWH","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
